{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import math\n",
    "from torch.utils import data\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from train import train_epoch, eval_epoch, Dataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "basis = torch.load(\"kernel_basis.pt\")\n",
    "train_direc = \"/global/cscratch1/sd/roseyu/Eliza/TF-net/Data/data_64/sample_\"\n",
    "img_direc = \"/global/cscratch1/sd/roseyu/Eliza/Img\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, l = 3, sout = 5, activation = True):\n",
    "        super(scale_conv2d, self).__init__()\n",
    "        self.out_channels= out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.l = l\n",
    "        self.sout = sout\n",
    "        self.activation = activation\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        weight_shape = (out_channels, l, 2, in_channels//2, kernel_size, kernel_size)\n",
    "        self.stdv = math.sqrt(1. / (kernel_size * kernel_size * in_channels * l))\n",
    "        self.weights = nn.Parameter(torch.Tensor(*weight_shape))\n",
    "        self.reset_parameters()\n",
    "        self.batchnorm = nn.BatchNorm3d(sout)# affine=False\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.weights.data.uniform_(-self.stdv, self.stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.fill_(0)\n",
    "            \n",
    "    def shrink_kernel(self, kernel, up_scale):\n",
    "        up_scale = torch.tensor(up_scale).float()\n",
    "        pad_in = (torch.ceil(up_scale**2).int())*((kernel.shape[2]-1)//2)\n",
    "        pad_h = (torch.ceil(up_scale).int())*((kernel.shape[3]-1)//2)\n",
    "        pad_w = (torch.ceil(up_scale).int())*((kernel.shape[4]-1)//2)\n",
    "        padded_kernel = F.pad(kernel, (pad_w, pad_w, pad_h, pad_h, pad_in, pad_in))\n",
    "        delta = up_scale%1\n",
    "        if delta == 0:\n",
    "            shrink_factor = 1\n",
    "        else:\n",
    "            # shrink_factor for coordinates if the kernel is over shrunk.\n",
    "            shrink_factor = (((kernel.shape[4]-1))/(padded_kernel.shape[-1]-1)*(up_scale+1))\n",
    "            # Adjustment to deal with weird filtering on the grid sample function.\n",
    "            shrink_factor = 1.5*(shrink_factor-0.5)**3 + 0.57   \n",
    "\n",
    "        grid = torch.meshgrid(torch.linspace(-1, 1, kernel.shape[2])*(shrink_factor**2),\n",
    "                              torch.linspace(-1, 1, kernel.shape[3])*shrink_factor, \n",
    "                              torch.linspace(-1, 1, kernel.shape[4])*shrink_factor)\n",
    "\n",
    "        grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "        new_kernel = F.grid_sample(padded_kernel, grid.to(device))\n",
    "        if kernel.shape[-1] - 2*up_scale > 0:\n",
    "            new_kernel = new_kernel * (kernel.shape[-1]**2/((kernel.shape[-1] - 2*up_scale)**2 + 0.01))\n",
    "        return new_kernel\n",
    "    \n",
    "    def dilate_kernel(self, kernel, dilation):\n",
    "        if dilation == 0:\n",
    "            return kernel \n",
    "\n",
    "        dilation = torch.tensor(dilation).float()\n",
    "        delta = dilation%1\n",
    "\n",
    "        d_in = torch.ceil(dilation**2).int()\n",
    "        new_in = kernel.shape[2] + (kernel.shape[2]-1)*d_in\n",
    "\n",
    "        d_h = torch.ceil(dilation).int()\n",
    "        new_h = kernel.shape[3] + (kernel.shape[3]-1)*d_h\n",
    "\n",
    "        d_w = torch.ceil(dilation).int()\n",
    "        new_w = kernel.shape[4] + (kernel.shape[4]-1)*d_h\n",
    "\n",
    "        new_kernel = torch.zeros(kernel.shape[0], kernel.shape[1], new_in, new_h, new_w)\n",
    "        new_kernel[:,:,::(d_in+1),::(d_h+1), ::(d_w+1)] = kernel\n",
    "        shrink_factor = 1\n",
    "        # shrink coordinates if the kernel is over dilated.\n",
    "        if delta != 0:\n",
    "            new_kernel = F.pad(new_kernel, ((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "\n",
    "            shrink_factor = (new_kernel.shape[-1] - 1 - (kernel.shape[4]-1)*(delta))/(new_kernel.shape[-1] - 1) \n",
    "            grid = torch.meshgrid(torch.linspace(-1, 1, new_in)*(shrink_factor**2), \n",
    "                                  torch.linspace(-1, 1, new_h)*shrink_factor, \n",
    "                                  torch.linspace(-1, 1, new_w)*shrink_factor)\n",
    "\n",
    "            grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                              grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                              grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "            new_kernel = F.grid_sample(new_kernel, grid)         \n",
    "            #new_kernel = new_kernel/new_kernel.sum()*kernel.sum()\n",
    "        return new_kernel[:,:,-kernel.shape[2]:]\n",
    "    \n",
    "    \n",
    "    def forward(self, xx):\n",
    "        #print(self.weights.shape, xx.shape)\n",
    "        out = []\n",
    "        for s in range(self.sout):\n",
    "            t = np.minimum(s + self.l, self.sout)\n",
    "            inp = xx[:,s:t].reshape(xx.shape[0], -1, xx.shape[-2], xx.shape[-1])\n",
    "            w = self.weights[:,:(t-s),:,:,:].reshape(self.out_channels, 2*(t-s), self.in_channels//2, self.kernel_size, self.kernel_size).to(device)\n",
    "            \n",
    "            if (s - self.sout//2) < 0:\n",
    "                new_kernel = self.shrink_kernel(w, (self.sout//2 - s)/2).to(device)\n",
    "            elif (s - self.sout//2) > 0:\n",
    "                new_kernel = self.dilate_kernel(w, (s - self.sout//2)/2).to(device)\n",
    "            else:\n",
    "                new_kernel = w.to(device)\n",
    "    \n",
    "            new_kernel = new_kernel.reshape(self.out_channels, (t-s)*self.in_channels, new_kernel.shape[-2], new_kernel.shape[-1])\n",
    "            conv = F.conv2d(inp, new_kernel, padding = ((new_kernel.shape[-2]-1)//2, (new_kernel.shape[-1]-1)//2))# bias = self.bias,\n",
    "                 \n",
    "            out.append(conv.unsqueeze(1))\n",
    "\n",
    "        out = torch.cat(out, dim = 1) \n",
    "        \n",
    "        # Activation Function\n",
    "        if self.activation: \n",
    "            #out = self.batchnorm(out)\n",
    "            out = F.leaky_relu(out)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "class scale_cnn(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, hidden_dim, num_layers, kernel_size, activation = False):\n",
    "        super(scale_cnn, self).__init__()\n",
    "        layers = [scale_conv2d(input_channels, hidden_dim, kernel_size, activation=activation)] + \\\n",
    "                 [scale_conv2d(hidden_dim, hidden_dim, kernel_size, activation=activation) for i in range(num_layers - 2)] + \\\n",
    "                 [scale_conv2d(hidden_dim, 2, kernel_size, sout = 1, activation=False)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, xx):\n",
    "        return self.layers(xx).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ResNet_1\"\n",
    "min_mse = 0.8\n",
    "kernel_size = 3\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.0001\n",
    "input_length = 7\n",
    "output_length = 1\n",
    "batch_size = 2\n",
    "\n",
    "train_indices = list(range(0, 10))\n",
    "valid_indices = list(range(10, 15))\n",
    "\n",
    "train_set = Dataset(train_indices, input_length, 40, output_length, train_direc)\n",
    "valid_set = Dataset(valid_indices, input_length, 40, 6, train_direc)\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "print(\"Initializing...\")\n",
    "model = scale_cnn(activation = \"leakyrelu\", input_channels = input_length*2, hidden_dim = hidden_dim, num_layers = num_layers, \n",
    "                  output_channels = output_length, kernel_size = kernel_size).to(device)#\n",
    "print(\"Done\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate,betas=(0.9, 0.999), weight_decay=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=0.9)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for i in range(30):\n",
    "    start = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.train()\n",
    "    train_mse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "    model.eval()\n",
    "    mse, _, _ = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_mse.append(mse)\n",
    "\n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1] \n",
    "        best_model = model\n",
    "        torch.save(model, name + \".pth\")\n",
    "    end = time.time()\n",
    "    if (len(train_mse) > 45 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "            break\n",
    "    print(i+1, train_mse[-1], valid_mse[-1], round((end-start)/60,5), format(get_lr(optimizer), \"5.2e\"), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rot (+ UM + Scale)\n",
    "- [x] test for equivariance: check Scale, Rot, UM\n",
    "- [x] train on untransformed, test on Scale + Rot + UM\n",
    "- [x] train on random Scale + Rot + UM, test on Scale + Rot + UM (same dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, l = 3, sout = 5, activation = True):\n",
    "        super(scale_conv2d, self).__init__()\n",
    "        self.out_channels= out_channels\n",
    "        self.in_channels = in_channels\n",
    "        self.l = l\n",
    "        self.sout = sout\n",
    "        self.activation = activation\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        weight_shape = (out_channels, l, 2, in_channels//2, kernel_size, kernel_size)\n",
    "        self.stdv = math.sqrt(1. / (kernel_size * kernel_size * in_channels * l))\n",
    "        self.weights = nn.Parameter(torch.Tensor(*weight_shape))\n",
    "        self.reset_parameters()\n",
    "        self.batchnorm = nn.BatchNorm3d(sout)# affine=False\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.weights.data.uniform_(-self.stdv, self.stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.fill_(0)\n",
    "            \n",
    "    def shrink_kernel(self, kernel, up_scale):\n",
    "        up_scale = torch.tensor(up_scale).float()\n",
    "        pad_in = (torch.ceil(up_scale**2).int())*((kernel.shape[2]-1)//2)\n",
    "        pad_h = (torch.ceil(up_scale).int())*((kernel.shape[3]-1)//2)\n",
    "        pad_w = (torch.ceil(up_scale).int())*((kernel.shape[4]-1)//2)\n",
    "        padded_kernel = F.pad(kernel, (pad_w, pad_w, pad_h, pad_h, pad_in, pad_in))\n",
    "        delta = up_scale%1\n",
    "        if delta == 0:\n",
    "            shrink_factor = 1\n",
    "        else:\n",
    "            # shrink_factor for coordinates if the kernel is over shrunk.\n",
    "            shrink_factor = (((kernel.shape[4]-1))/(padded_kernel.shape[-1]-1)*(up_scale+1))\n",
    "            # Adjustment to deal with weird filtering on the grid sample function.\n",
    "            shrink_factor = 1.5*(shrink_factor-0.5)**3 + 0.57   \n",
    "\n",
    "        grid = torch.meshgrid(torch.linspace(-1, 1, kernel.shape[2])*(shrink_factor**2),\n",
    "                              torch.linspace(-1, 1, kernel.shape[3])*shrink_factor, \n",
    "                              torch.linspace(-1, 1, kernel.shape[4])*shrink_factor)\n",
    "\n",
    "        grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "        new_kernel = F.grid_sample(padded_kernel, grid.to(device))\n",
    "        if kernel.shape[-1] - 2*up_scale > 0:\n",
    "            new_kernel = new_kernel * (kernel.shape[-1]**2/((kernel.shape[-1] - 2*up_scale)**2 + 0.01))\n",
    "        return new_kernel\n",
    "    \n",
    "    def dilate_kernel(self, kernel, dilation):\n",
    "        if dilation == 0:\n",
    "            return kernel \n",
    "\n",
    "        dilation = torch.tensor(dilation).float()\n",
    "        delta = dilation%1\n",
    "\n",
    "        d_in = torch.ceil(dilation**2).int()\n",
    "        new_in = kernel.shape[2] + (kernel.shape[2]-1)*d_in\n",
    "\n",
    "        d_h = torch.ceil(dilation).int()\n",
    "        new_h = kernel.shape[3] + (kernel.shape[3]-1)*d_h\n",
    "\n",
    "        d_w = torch.ceil(dilation).int()\n",
    "        new_w = kernel.shape[4] + (kernel.shape[4]-1)*d_h\n",
    "\n",
    "        new_kernel = torch.zeros(kernel.shape[0], kernel.shape[1], new_in, new_h, new_w)\n",
    "        new_kernel[:,:,::(d_in+1),::(d_h+1), ::(d_w+1)] = kernel\n",
    "        shrink_factor = 1\n",
    "        # shrink coordinates if the kernel is over dilated.\n",
    "        if delta != 0:\n",
    "            new_kernel = F.pad(new_kernel, ((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "\n",
    "            shrink_factor = (new_kernel.shape[-1] - 1 - (kernel.shape[4]-1)*(delta))/(new_kernel.shape[-1] - 1) \n",
    "            grid = torch.meshgrid(torch.linspace(-1, 1, new_in)*(shrink_factor**2), \n",
    "                                  torch.linspace(-1, 1, new_h)*shrink_factor, \n",
    "                                  torch.linspace(-1, 1, new_w)*shrink_factor)\n",
    "\n",
    "            grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                              grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                              grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "            new_kernel = F.grid_sample(new_kernel, grid)         \n",
    "            #new_kernel = new_kernel/new_kernel.sum()*kernel.sum()\n",
    "        return new_kernel[:,:,-kernel.shape[2]:]\n",
    "    \n",
    "    \n",
    "    def forward(self, xx):\n",
    "        #print(self.weights.shape, xx.shape)\n",
    "        out = []\n",
    "        for s in range(self.sout):\n",
    "            t = np.minimum(s + self.l, self.sout)\n",
    "            inp = xx[:,s:t].reshape(xx.shape[0], -1, xx.shape[-2], xx.shape[-1])\n",
    "            w = self.weights[:,:(t-s),:,:,:].reshape(self.out_channels, 2*(t-s), self.in_channels//2, self.kernel_size, self.kernel_size).to(device)\n",
    "            \n",
    "            if (s - self.sout//2) < 0:\n",
    "                new_kernel = self.shrink_kernel(w, (self.sout//2 - s)/2).to(device)\n",
    "            elif (s - self.sout//2) > 0:\n",
    "                new_kernel = self.dilate_kernel(w, (s - self.sout//2)/2).to(device)\n",
    "            else:\n",
    "                new_kernel = w.to(device)\n",
    "    \n",
    "            new_kernel = new_kernel.reshape(self.out_channels, (t-s)*self.in_channels, new_kernel.shape[-2], new_kernel.shape[-1])\n",
    "            conv = F.conv2d(inp, new_kernel, padding = ((new_kernel.shape[-2]-1)//2, (new_kernel.shape[-1]-1)//2))# bias = self.bias,\n",
    "                 \n",
    "            out.append(conv.unsqueeze(1))\n",
    "\n",
    "        out = torch.cat(out, dim = 1) \n",
    "        \n",
    "        # Activation Function\n",
    "        if self.activation: \n",
    "            #out = self.batchnorm(out)\n",
    "            out = F.leaky_relu(out)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "class rot_um_scale_cnn(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, hidden_dim, num_layers, kernel_size, activation = False):\n",
    "        super(rot_um_scale_cnn, self).__init__()\n",
    "        layers = [scale_conv2d(input_channels, hidden_dim, kernel_size, activation=activation)] + \\\n",
    "                 [scale_conv2d(hidden_dim, hidden_dim, kernel_size, activation=activation) for i in range(num_layers - 2)] + \\\n",
    "                 [scale_conv2d(hidden_dim, 2, kernel_size, sout = 1, activation=False)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, xx):\n",
    "        return self.layers(xx).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ResNet_1\"\n",
    "min_mse = 0.8\n",
    "kernel_size = 3\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.0001\n",
    "input_length = 7\n",
    "output_length = 1\n",
    "batch_size = 2\n",
    "\n",
    "train_indices = list(range(0, 10))\n",
    "valid_indices = list(range(10, 15))\n",
    "\n",
    "train_set = Dataset(train_indices, input_length, 40, output_length, train_direc)\n",
    "valid_set = Dataset(valid_indices, input_length, 40, 6, train_direc)\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "Done\n",
      "1 1.07841 1.00667 0.04488 9.00e-05 ResNet_1\n",
      "2 0.95766 0.91745 0.04434 8.10e-05 ResNet_1\n",
      "3 0.85471 0.83669 0.04504 7.29e-05 ResNet_1\n",
      "4 0.76767 0.76745 0.04657 6.56e-05 ResNet_1\n",
      "5 0.69818 0.70975 0.04521 5.90e-05 ResNet_1\n",
      "6 0.64068 0.66289 0.04518 5.31e-05 ResNet_1\n",
      "7 0.59717 0.62521 0.04548 4.78e-05 ResNet_1\n",
      "8 0.56001 0.59547 0.04482 4.30e-05 ResNet_1\n",
      "9 0.53 0.57203 0.04498 3.87e-05 ResNet_1\n",
      "10 0.50727 0.55283 0.04623 3.49e-05 ResNet_1\n",
      "11 0.48842 0.5369 0.0454 3.14e-05 ResNet_1\n",
      "12 0.47213 0.52392 0.04444 2.82e-05 ResNet_1\n",
      "13 0.45931 0.51286 0.04591 2.54e-05 ResNet_1\n",
      "14 0.44857 0.50331 0.04591 2.29e-05 ResNet_1\n",
      "15 0.43903 0.49518 0.04519 2.06e-05 ResNet_1\n",
      "16 0.43118 0.48808 0.04536 1.85e-05 ResNet_1\n",
      "17 0.4249 0.48175 0.04547 1.67e-05 ResNet_1\n",
      "18 0.41883 0.47638 0.04595 1.50e-05 ResNet_1\n",
      "19 0.4144 0.47142 0.04498 1.35e-05 ResNet_1\n",
      "20 0.41009 0.46711 0.04562 1.22e-05 ResNet_1\n",
      "21 0.40646 0.4632 0.04422 1.09e-05 ResNet_1\n",
      "22 0.40304 0.45986 0.04445 9.85e-06 ResNet_1\n",
      "23 0.40008 0.45693 0.04467 8.86e-06 ResNet_1\n",
      "24 0.39759 0.45436 0.04505 7.98e-06 ResNet_1\n",
      "25 0.39576 0.45194 0.04378 7.18e-06 ResNet_1\n",
      "26 0.3937 0.44981 0.04428 6.46e-06 ResNet_1\n",
      "27 0.3919 0.44795 0.04307 5.81e-06 ResNet_1\n",
      "28 0.39057 0.44623 0.04337 5.23e-06 ResNet_1\n",
      "29 0.38916 0.44467 0.04114 4.71e-06 ResNet_1\n",
      "30 0.38787 0.44334 0.04301 4.24e-06 ResNet_1\n"
     ]
    }
   ],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "print(\"Initializing...\")\n",
    "model = rot_um_scale_cnn(activation = \"leakyrelu\", input_channels = input_length*2, hidden_dim = hidden_dim, num_layers = num_layers, \n",
    "                  output_channels = output_length, kernel_size = kernel_size).to(device)#\n",
    "print(\"Done\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate,betas=(0.9, 0.999), weight_decay=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=0.9)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for i in range(30):\n",
    "    start = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.train()\n",
    "    train_mse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "    model.eval()\n",
    "    mse, _, _ = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_mse.append(mse)\n",
    "\n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1] \n",
    "        best_model = model\n",
    "        torch.save(model, name + \".pth\")\n",
    "    end = time.time()\n",
    "    if (len(train_mse) > 45 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "            break\n",
    "    print(i+1, train_mse[-1], valid_mse[-1], round((end-start)/60,5), format(get_lr(optimizer), \"5.2e\"), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "direc = 0\n",
    "step = 0\n",
    "fig=plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cnn_trues[idx,step,direc])\n",
    "plt.title(\"Target\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cnn_preds[idx,step,direc])\n",
    "plt.title(\"Prediction\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "fig.savefig(img_direc + '/rot_um_scale_target_pred', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rot\n",
    "fig=plt.figure(figsize=(10, 4))\n",
    "initial_kernel = model.layers[0].initial_kernel.cpu().data.numpy()\n",
    "trained_kernel = torch.einsum(\"abcd, cdefgh -> abefgh\",  (model.layers[0].params, model.layers[0].basis.to(device))).cpu().data.numpy()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(initial_kernel[:,0,:,:,0,0].flatten(), bins = 30)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(trained_kernel[:,0,:,:,0,0].flatten(), bins = 30)\n",
    "#plt.xlim(-0.5, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = torch.load(\"/global/cscratch1/sd/roseyu/Eliza/Rot-UM/results.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resnet[\"preds\"][0,0,0])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resnet[\"trues\"][0,0,0])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotationaly symmetric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "PIL = transforms.ToPILImage()\n",
    "TTen = transforms.ToTensor()\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def normalize(tensor):\n",
    "    return (tensor - torch.min(tensor))/(torch.max(tensor) - torch.min(tensor))\n",
    "\n",
    "def rotate(img, degree):\n",
    "    #img shape 2*128*128\n",
    "    #2*2 2*1*128*128 -> 2*1*128*128\n",
    "    theta = torch.tensor(degree/180*np.pi)\n",
    "    rot_m = torch.tensor([[torch.cos(theta), -torch.sin(theta)], [torch.sin(theta), torch.cos(theta)]])\n",
    "    img = torch.einsum(\"ab, bcde -> acde\",(rot_m, img.unsqueeze(1))).squeeze(1)\n",
    "    mmin = torch.min(img)\n",
    "    mmax = torch.max(img)\n",
    "    img = normalize(img).data.numpy()\n",
    "    x = TTen(TF.rotate(Image.fromarray(np.uint8(img[0]*255)),degree, expand =  True))\n",
    "    y = TTen(TF.rotate(Image.fromarray(np.uint8(img[1]*255)),degree, expand =  True))\n",
    "    rot_img = torch.cat([x, y], dim = 0)\n",
    "    rot_img[rot_img!=0] = normalize(rot_img[rot_img!=0])\n",
    "    rot_img[rot_img!=0] = rot_img[rot_img!=0]*(mmax - mmin) + mmin\n",
    "    return rot_img\n",
    "\n",
    "train_direc = \"/global/cscratch1/sd/roseyu/Eliza/TF-net/Data/data_128/sample_\"\n",
    "input_length = 2\n",
    "output_length = 3\n",
    "batch_size = 1\n",
    "train_indices = list(range(0, 1))\n",
    "train_set = Dataset(train_indices, input_length, 40, output_length, train_direc, True)\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "for xx, yy in train_loader:\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "degree = 90\n",
    "\n",
    "# model = Ani_layer(input_channels = 1, output_channels = 1, kernel_size = 7).to(device)\n",
    "model = rot_um_cnn(input_channels = 2, output_channels = 1, hidden_dim = 128, num_layers = 4, kernel_size = 7, activation = \"tanh\").to(device)\n",
    "\n",
    "rot_xx = torch.cat([rotate(xx[0,:2], degree).unsqueeze(0), rotate(xx[0,-2:], degree).unsqueeze(0)] , dim = 1)#rotate(xx[0,0], degree).unsqueeze(0)\n",
    "\n",
    "rot_xx_out = model(rot_xx.to(device))\n",
    "              \n",
    "xx_out_rot = rotate((rot_xx_out[0]).cpu(), -degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_out = model(xx.to(device))\n",
    "\n",
    "rot_xx = torch.cat([rotate(xx[0,:2], degree).unsqueeze(0), rotate(xx[0,-2:], degree).unsqueeze(0)] , dim = 1)#rotate(xx[0,0], degree).unsqueeze(0)\n",
    "\n",
    "rot_xx_out = model(rot_xx.to(device))\n",
    "                \n",
    "xx_out_rot = rotate((rot_xx_out[0]).cpu(), -degree)\n",
    "\n",
    "direc = 0\n",
    "fig=plt.figure(figsize=(18, 10))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(xx[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$X$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(xx_out[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$F(X)$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(rot_xx[0, direc].cpu().data.numpy())\n",
    "plt.title(r\"$rot(X)$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(rot_xx_out[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$F(rot(X))$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(xx_out_rot[direc].cpu().data.numpy())\n",
    "plt.title(r\"$rot^{-1}(F(rot(X)))$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.suptitle(\"Conv2d\", size = 30)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(img_direc + '/rot_um_conv2d_rot', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_motion(img, unit_vector):\n",
    "    return img + torch.FloatTensor(unit_vector).repeat(img.shape[1]//2, img.shape[-1]**2).view(img.shape)\n",
    "def sample_spherical(npoints, ndim=3):\n",
    "    vec = np.random.randn(ndim, npoints)\n",
    "    vec /= np.linalg.norm(vec, axis=0)\n",
    "    return vec\n",
    "um_vector = sample_spherical(1, 2)\n",
    "rot_um_xx = uniform_motion(rot_xx, um_vector)\n",
    "plt.imshow(rot_um_xx[0, direc].cpu().data.numpy())\n",
    "plt.title(r\"$um(rot(X))$\", size = 15)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    \"\"\"Compute root mean squared error\"\"\"\n",
    "    return torch.sqrt(torch.mean((y - y_hat).pow(2)))\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    \"\"\"Compute mean squared error\"\"\"\n",
    "    return torch.mean((y - y_hat).pow(2))\n",
    "\n",
    "xx_out_sample = xx_out[0,direc].cpu()\n",
    "xx_out_rot_sample = xx_out_rot[direc].cpu()\n",
    "print(rmse(xx_out_sample, xx_out_rot_sample))\n",
    "print(mse(xx_out_sample, xx_out_rot_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xx_out_rot[direc].cpu().data.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xx_out[0,direc].cpu().data.numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UM symmetric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spherical(npoints, ndim=3):\n",
    "    vec = np.random.randn(ndim, npoints)\n",
    "    vec /= np.linalg.norm(vec, axis=0)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    return (tensor - torch.min(tensor))/(torch.max(tensor) - torch.min(tensor))\n",
    "\n",
    "def uniform_motion(img, unit_vector):\n",
    "    return img + torch.FloatTensor(unit_vector).repeat(img.shape[1]//2, img.shape[-1]**2).view(img.shape)\n",
    "\n",
    "train_direc = \"/global/cscratch1/sd/roseyu/Eliza/TF-net/Data/data_128/sample_\"\n",
    "input_length = 2\n",
    "output_length = 3\n",
    "batch_size = 1\n",
    "train_indices = list(range(0, 1))\n",
    "train_set = Dataset(train_indices, input_length, 40, output_length, train_direc, True)\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "for xx, yy in train_loader:\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "um_vector = sample_spherical(1, 2)\n",
    "\n",
    "# model = Ani_layer(input_channels = 1, output_channels = 1, kernel_size = 7).to(device)\n",
    "model = rot_um_cnn(input_channels = 2, output_channels = 1, hidden_dim = 128, num_layers = 4, kernel_size = 7, activation = \"tanh\").to(device)\n",
    "\n",
    "um_xx = uniform_motion(xx, um_vector)\n",
    "\n",
    "um_xx_out = model(um_xx.to(device))\n",
    "\n",
    "xx_out_um = uniform_motion((um_xx_out).cpu(), -um_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_out = model(xx.to(device))\n",
    "\n",
    "um_xx = uniform_motion(xx, um_vector)\n",
    "\n",
    "um_xx_out = model(um_xx.to(device))\n",
    "\n",
    "xx_out_um = uniform_motion((um_xx_out).cpu(), -um_vector)\n",
    "\n",
    "direc = 0\n",
    "fig=plt.figure(figsize=(18, 10))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(xx[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$X$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(xx_out[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$F(X)$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(um_xx[0, direc].cpu().data.numpy())\n",
    "plt.title(r\"$um(X)$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(um_xx_out[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$F(um(X))$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(xx_out_um[0, direc].cpu().data.numpy())\n",
    "plt.title(r\"$um^{-1}(F(um(X)))$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.suptitle(\"Conv2d\", size = 30)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(img_direc + '/rot_um_conv2d_um', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    \"\"\"Compute root mean squared error\"\"\"\n",
    "    return torch.sqrt(torch.mean((y - y_hat).pow(2)))\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    \"\"\"Compute root mean squared error\"\"\"\n",
    "    return torch.mean((y - y_hat).pow(2))\n",
    "\n",
    "xx_out_sample = xx_out[0,direc].cpu()\n",
    "xx_out_um_sample = xx_out_um[0, direc].cpu()\n",
    "print(rmse(xx_out_sample, xx_out_um_sample))\n",
    "print(mse(xx_out_sample, xx_out_um_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xx_out_rot[direc].cpu().data.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xx_out[0,direc].cpu().data.numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale symmetric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(img, factor):\n",
    "    scale_img = F.interpolate(img.unsqueeze(0), scale_factor = (1, factor, factor), mode=\"trilinear\", align_corners = True).squeeze(0)\n",
    "    return scale_img*(img.max() - img.min())/(scale_img.max() - scale_img.min())/factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_direc = \"/global/cscratch1/sd/roseyu/Eliza/TF-net/Data/data_128/sample_\"\n",
    "input_length = 2\n",
    "output_length = 3\n",
    "batch_size = 1\n",
    "train_indices = list(range(0, 1))\n",
    "train_set = Dataset(train_indices, input_length, 40, output_length, train_direc, True)\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "for xx, yy in train_loader:\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "factor = np.random.uniform(0.2, 2)\n",
    "\n",
    "# model = Ani_layer(input_channels = 1, output_channels = 1, kernel_size = 7).to(device)\n",
    "model = rot_um_scale_cnn(input_channels = 2, output_channels = 1, hidden_dim = 128, num_layers = 4, kernel_size = 7, activation = \"tanh\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_out = model(xx.to(device))\n",
    "\n",
    "scale_xx = scale(xx, factor)\n",
    "\n",
    "scale_xx_out = model(scale_xx.to(device))\n",
    "\n",
    "xx_out_scale = scale((scale_xx_out).cpu(), 1/factor)\n",
    "\n",
    "direc = 0\n",
    "fig=plt.figure(figsize=(18, 10))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(xx[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$X$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(xx_out[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$F(X)$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(scale_xx[0, direc].cpu().data.numpy())\n",
    "plt.title(r\"$scale(X)$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(scale_xx_out[0,direc].cpu().data.numpy())\n",
    "plt.title(r\"$F(scale(X))$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(xx_out_scale[0, direc].cpu().data.numpy())\n",
    "plt.title(r\"$scale^{-1}(F(scale(X)))$\", size = 15)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.suptitle(\"Conv2d\", size = 30)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(img_direc + '/rot_um_scale_conv2d_scale', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    \"\"\"Compute root mean squared error\"\"\"\n",
    "    return torch.sqrt(torch.mean((y[:y_hat.shape[0], :y_hat.shape[1]] - y_hat).pow(2)))\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    \"\"\"Compute root mean squared error\"\"\"\n",
    "    return torch.mean((y[:y_hat.shape[0], :y_hat.shape[1]] - y_hat).pow(2))\n",
    "\n",
    "xx_out_sample = xx_out[0,direc].cpu()\n",
    "xx_out_scale_sample = xx_out_scale[0, direc].cpu()\n",
    "print(rmse(xx_out_sample, xx_out_scale_sample))\n",
    "print(mse(xx_out_sample, xx_out_scale_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotMat(theta, inverse = False):\n",
    "    theta = torch.tensor(theta)\n",
    "    sin = torch.sin(theta)\n",
    "    cos = torch.cos(theta)\n",
    "    mat = torch.cat([cos.unsqueeze(1), sin.unsqueeze(1)*(-1), sin.unsqueeze(1), cos.unsqueeze(1)], dim = 1).reshape(-1,2,2) \n",
    "    if inverse:\n",
    "        return mat.inverse().float()\n",
    "    return mat.float()\n",
    "\n",
    "\n",
    "max_radius = 16\n",
    "min_radius = 0.5\n",
    "step_radius = 0.25\n",
    "num_radius = (max_radius - min_radius-1)/step_radius\n",
    "center_x = max_radius-1\n",
    "center_y = max_radius-1\n",
    "basis = torch.zeros(int(num_radius), 4, 31, 31, 2, 2)\n",
    "\n",
    "Ms = [torch.tensor([[1.,0.],[0.,0.]]), torch.tensor([[0.,1.],[0.,0.]]), torch.tensor([[0.,0.],[1.,0.]]), torch.tensor([[0.,0.],[0.,1.]])]\n",
    "for rad_id in range(1, int(num_radius)):\n",
    "    rad = (rad_id-1) * step_radius + min_radius \n",
    "    for i in range(len(Ms)):\n",
    "        for rr in np.linspace(rad - 0.25, rad + 0.25, 6):\n",
    "            theta = np.linspace(0, np.pi*2, int(500*rr//2))\n",
    "            x = (np.round(np.cos(theta)*rad)).astype(\"int32\") \n",
    "            y = (np.round(np.sin(theta)*rad)).astype(\"int32\")\n",
    "            id_x = center_x - y \n",
    "            id_y = center_y + x\n",
    "            out = torch.einsum(\"zac, zcd -> zad\", (torch.einsum(\"zab, bc->zac\", (rotMat(theta), Ms[i])), rotMat(theta, inverse = True)))\n",
    "            for j in range(len(x)):\n",
    "                basis[rad_id, i, id_x[j], id_y[j]] += out[j] \n",
    "                \n",
    "for i in range(len(Ms)):\n",
    "    basis[0, i, center_x, center_y] = 500*Ms[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(basis[1,0,:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis[1,3,15,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis[1,0,15,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(basis/500, \"kernel_basis.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X, Y = np.meshgrid(np.arange(-1, 2, 1), np.arange(1, -2, -1))\n",
    "\n",
    "x_shape = X.shape\n",
    "\n",
    "U = basis[0,0,:,:,0,0]\n",
    "V = basis[0,0,:,:,1,0]\n",
    "\n",
    "U2 = basis[0,0,:,:,0,1]\n",
    "V2 = basis[0,0,:,:,1,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V, units='xy' ,scale=2, color='green')\n",
    "q = ax.quiver(X, Y, U2, V2, units='xy' ,scale=2, color='red')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X, Y = np.meshgrid(np.arange(-1, 2, 1), np.arange(1, -2, -1))\n",
    "\n",
    "x_shape = X.shape\n",
    "\n",
    "U = basis[0,0,:,:,0,1]\n",
    "V = basis[0,0,:,:,1,1]\n",
    "\n",
    "def rotate_vec(img, degree):\n",
    "    #img shape 2*128*128\n",
    "    img = torch.tensor(img).float()\n",
    "    #2*2 2*1*128*128 -> 2*1*128*128\n",
    "    \n",
    "    theta = torch.tensor(degree/180*np.pi)\n",
    "    rot_m = torch.tensor([[torch.cos(theta), -torch.sin(theta)], [torch.sin(theta), torch.cos(theta)]])\n",
    "    img = torch.einsum(\"ab, bcde -> acde\",(rot_m, img.unsqueeze(1))).squeeze(1)\n",
    "    return img\n",
    "\n",
    "stack = np.stack([U,V])\n",
    "rot_U = rotate_vec(stack, 90)[0]\n",
    "rot_V = rotate_vec(stack, 90)[1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V, units='xy' ,scale=2, color='red')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(basis, \"kernel_basis.pt\")\n",
    "print(\"Basic Matrices Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = torch.load(\"kernel_basis.pt\")\n",
    "basis = torch.sum(basis, dim = 0).data.numpy()\n",
    "plt.imshow(basis[0,:,:,0,1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotMat(theta, inverse = False):\n",
    "    theta = torch.tensor(theta)\n",
    "    sin = torch.sin(theta)\n",
    "    cos = torch.cos(theta)\n",
    "    mat = torch.cat([cos.unsqueeze(1), sin.unsqueeze(1)*(-1), sin.unsqueeze(1), cos.unsqueeze(1)], dim = 1).reshape(-1,2,2) \n",
    "    if inverse:\n",
    "        return mat.inverse().float()\n",
    "    return mat.float()\n",
    "\n",
    "basis = torch.zeros(2, 4, 3, 3, 2, 2)\n",
    "Ms = [torch.tensor([[1.,0.],[0.,0.]]), torch.tensor([[0.,1.],[0.,0.]]), torch.tensor([[0.,0.],[1.,0.]]), torch.tensor([[0.,0.],[0.,1.]])]\n",
    "for rad in range(1, 2):\n",
    "    for i in range(len(Ms)):\n",
    "        for rr in np.linspace(rad - 0.25, rad + 0.25, 6):\n",
    "            theta = np.linspace(0, np.pi*2, int(500*rr//2))\n",
    "            x = (np.round(np.cos(theta)*rad)).astype(\"int32\") + 1\n",
    "            y = (np.round(np.sin(theta)*rad)).astype(\"int32\") + 1\n",
    "            out = torch.einsum(\"zac, zcd -> zad\", (torch.einsum(\"zab, bc->zac\", (rotMat(theta), Ms[i])), rotMat(theta, inverse = True)))\n",
    "            for j in range(len(x)):\n",
    "                basis[rad-1, i, x[j], y[j]] += out[j]     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img, degree):\n",
    "    #img shape 2*128*128\n",
    "    #2*2 2*1*128*128 -> 2*1*128*128\n",
    "    theta = torch.tensor(degree/180*np.pi)\n",
    "    rot_m = torch.tensor([[torch.cos(theta), -torch.sin(theta)], [torch.sin(theta), torch.cos(theta)]])\n",
    "    img = torch.einsum(\"ab, bcde -> acde\",(rot_m, img.unsqueeze(1))).squeeze(1)\n",
    "    mmin = torch.min(img)\n",
    "    mmax = torch.max(img)\n",
    "    img = normalize(img).data.numpy()\n",
    "    x = TTen(TF.rotate(Image.fromarray(np.uint8(img[0]*255)),degree, expand =  True))\n",
    "    y = TTen(TF.rotate(Image.fromarray(np.uint8(img[1]*255)),degree, expand =  True))\n",
    "    rot_img = torch.cat([x, y], dim = 0)\n",
    "    rot_img[rot_img!=0] = normalize(rot_img[rot_img!=0])\n",
    "    rot_img[rot_img!=0] = rot_img[rot_img!=0]*(mmax - mmin) + mmin\n",
    "    return rot_img\n",
    "\n",
    "def rotate_img(img, degree):\n",
    "    img = torch.tensor(img).float()\n",
    "    mmin = torch.min(img)\n",
    "    mmax = torch.max(img)\n",
    "    img = normalize(img).data.numpy()\n",
    "    x = TTen(TF.rotate(Image.fromarray(np.uint8(img[0]*255)),degree,expand =  True))\n",
    "    y = TTen(TF.rotate(Image.fromarray(np.uint8(img[1]*255)),degree,expand =  True))\n",
    "    rot_img = torch.cat([x, y], dim = 0)\n",
    "    #print(np.max(img), np.min(img), torch.max(rot_img), torch.min(rot_img))\n",
    "    rot_img = rot_img*(mmax - mmin) + mmin\n",
    "    return rot_img.cpu().data.numpy()\n",
    "\n",
    "def rotate_vec(img, degree):\n",
    "    #img shape 2*128*128\n",
    "    img = torch.tensor(img).float()\n",
    "    #2*2 2*1*128*128 -> 2*1*128*128\n",
    "    \n",
    "    theta = torch.tensor(degree/180*np.pi)\n",
    "    rot_m = torch.tensor([[torch.cos(theta), -torch.sin(theta)], [torch.sin(theta), torch.cos(theta)]])\n",
    "    img = torch.einsum(\"ab, bcde -> acde\",(rot_m, img.unsqueeze(1))).squeeze(1)\n",
    "    return img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X, Y = np.meshgrid(np.arange(-1, 2, 1), np.arange(1, -2, -1))\n",
    "\n",
    "x_shape = X.shape\n",
    "\n",
    "U = np.ones(x_shape)\n",
    "V = np.zeros(x_shape)\n",
    "\n",
    "#for i in range(x_shape[0]):\n",
    " #   for j in range(x_shape[1]):\n",
    "       # U[i,j] = 1-i/10\n",
    "        #V[i,j] = np.sin(i/20*7)\n",
    "\n",
    "U[2,2] = 0\n",
    "V[2,2] = 1\n",
    "\n",
    "\n",
    "stack = np.stack([U,V])\n",
    "rot_U = rotate_vec(stack, 90)[0]\n",
    "rot_V = rotate_vec(stack, 90)[1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V, units='xy' ,scale=2, color='red')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, rot_U, rot_V, units='xy' ,scale=2, color='red')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.show()\n",
    "\n",
    "stack = np.stack([rot_U,rot_V])\n",
    "rot_U2 = rotate_img(stack, 90)[0]\n",
    "rot_V2 = rotate_img(stack, 90)[1]\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, rot_U2, rot_V2, units='xy' ,scale=2, color='red')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, hidden_dim,  kernel_size, num_layers, activation = False, bias = True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(input_channels*2, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2, bias = bias),\n",
    "            #nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2, bias = bias),\n",
    "            #nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2, bias = bias),\n",
    "            #nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2, bias = bias),\n",
    "            #nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, output_channels*2, kernel_size = kernel_size, padding = (kernel_size-1)//2, bias = bias)\n",
    "        )\n",
    "        self.initial_params = self.layer[0].weight.clone()\n",
    "         \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "    def forward(self, xx):\n",
    "        xx = xx.reshape(xx.shape[0], -1, xx.shape[-2], xx.shape[-1])\n",
    "        out = self.layer(xx)\n",
    "        out = out.reshape(out.shape[0], out.shape[1]//2, 2, xx.shape[-2], xx.shape[-1])\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
